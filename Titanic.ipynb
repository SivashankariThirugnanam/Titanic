{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891c4e50",
   "metadata": {},
   "source": [
    "# TITANIC PROJECT\n",
    "\n",
    "The Titanic dataset is a well-known dataset in the field of data analysis and machine learning. It contains information about the passengers who were aboard the Titanic during its maiden voyage, which famously sank in 1912. The dataset includes details about each passenger's age, gender, class of ticket, fare, and whether or not they survived the sinking.The titanic dataset is a widely popular dataset which predicts the survival of people on board with given features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5ba4b",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed69fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# for mathemaical operations\n",
    "import numpy as np\n",
    "\n",
    "# for dataframe manipulations\n",
    "import pandas as pd\n",
    "\n",
    "#for model building\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fd8bc",
   "metadata": {},
   "source": [
    "# Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c81f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets read the csv file from directory\n",
    "Titanic = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28395efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the head of the dataset\n",
    "Titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82396ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the shape of the dataset\n",
    "Titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93162b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets expand to view all the columns and rows\n",
    "pd.set_option(\"max_columns\", 20)\n",
    "pd.set_option(\"max_rows\", 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target column here is 'Survived' , we will relocate the column \n",
    "col_list = list(Titanic.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the column list again after relocating\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now reindex our columns\n",
    "\n",
    "changed_indexed_columns = ['PassengerId', 'Pclass', 'Name', 'Sex', \n",
    "'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', \n",
    "'Survived']\n",
    "Titanic = Titanic[changed_indexed_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b044c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data\n",
    "Titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e704c24",
   "metadata": {},
   "source": [
    "#                                     Columns Exploring\n",
    "\n",
    "We will one by one explore each columns and take action on the same according to it's importance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pclass refers to the passenger class in the ship \n",
    "# this might play an important role in terms of survival \n",
    "# as may be first class passengers are given more importance during Evacuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce144473",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic[\"Pclass\"].value_counts() # to check the values in certain row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values in the data\n",
    "print(f\" Missing value in the Pclass column is: {Titanic['Pclass'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic[\"Pclass\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb23b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally the name column should not have any affect on survival\n",
    "# We can drop the name column for the same reason\n",
    "# Before we drop the column we will try to find out how the data is divided with age \n",
    "# we will split the names to identify the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afe23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic['Name'] = Titanic['Name'].str.split(', ').str[1]\n",
    "Titanic['Name'] = Titanic['Name'].str.split('.').str[0]\n",
    "Titanic['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the maximum age for 'Master' \n",
    "# This will determine the child age high limit in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6effbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_age = Titanic[Titanic['Name'] == 'Master']\n",
    "child_age['Age'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01371ae",
   "metadata": {},
   "source": [
    "#we can see that maximum age limit given here is 29.This can't be considered so we will take 15 as the highest age for \n",
    "children in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.drop(['Name'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Children are given more impotance during evacuation\n",
    "# so we will segreagte our sex and age column together and make new columns\n",
    "# Let's check the statistical distribution of the 'Age' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ead0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the maximum age in data is {Titanic['Age'].max()}\")\n",
    "print(f\"the minimum age in data is {Titanic['Age'].min()}\")\n",
    "print(f\"the average age in data is {Titanic['Age'].mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58417328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the missing value in the data\n",
    "print(f\"The missing value in age column is: {Titanic['Age'].isnull().sum()}\")\n",
    "print(f\"The missing value share in age column is: {Titanic['Age'].isnull().sum()/len(Titanic['Age'])}\")\n",
    "len(Titanic['Age']) #177/891\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6779b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The missing value share here is just 20%\n",
    "# So we will fill this missing values in 'mean' strategy usning fillna\n",
    "Titanic['Age'].fillna(Titanic['Age'].mean(),inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6639701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The missing value in age column is :{Titanic['Age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's check the missing value in the 'sex' column\n",
    "print(f\"The missing value in sex column is :{Titanic['Sex'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's combine sex and age column to cometother into a new column\n",
    "# we will construct male,female child and male , female adult column\n",
    "# Below 15 years of age is child and above 15 years will be treated asadults\n",
    "# We will python functions her"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bece3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_groups(Titanic):\n",
    "    if Titanic['Sex'] == 'male' and Titanic['Age'] >= 15:\n",
    "        return 'Male Adult'\n",
    "    elif Titanic['Sex'] == 'male' and Titanic['Age'] <= 15:\n",
    "        return 'Male Child'\n",
    "    elif Titanic['Sex'] == 'female' and Titanic['Age'] >= 15:\n",
    "        return 'Female Adult'\n",
    "    elif Titanic['Sex'] == 'female' and Titanic['Age'] <= 15:\n",
    "        return 'Female Child'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the grouping in the dataframe\n",
    "Titanic['Passenger_group'] = Titanic.apply(age_groups,axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the data\n",
    "Titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our data is properly grouped , we can go ahead and drop sex and age column\n",
    "Titanic.drop(['Sex','Age'],axis = 1,inplace = True)\n",
    "# Checking the data\n",
    "Titanic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b593ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked column is a categorical one so we need to convert it \n",
    "# Let's find it's missing values\n",
    "print(f\"the missing value in the data of embarked column: {Titanic['Embarked'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d48468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's handle the missing values in the column\n",
    "Titanic.fillna(Titanic['Embarked'].mode().iloc[0],inplace =True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cacc4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the missing value in the data of embarked column: {Titanic['Embarked'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert our categorical column of embarked into numerical by using labelEncoder\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "Titanic['Embarked']= le.fit_transform(Titanic['Embarked'])\n",
    "Titanic['Embarked'].value_counts().unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a683fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic['Passenger_group'] = le.fit_transform(Titanic['Passenger_group'])\n",
    "Titanic['Passenger_group'].value_counts().unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f394fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Survived\"\n",
    "x = Titanic.loc[:, Titanic.columns != col]\n",
    "y = Titanic.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758188ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x, columns = ['PassengerId', 'Pclass',\n",
    "'SibSp', 'Parch', 'Fare',\n",
    "'Embarked','Passenger_group'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "object= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe325192",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = object.fit_transform(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65743ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do our train test splitting now\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x ,y ,stratify = y , random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69f2a4",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f006a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Mtarix for Logistic Regression Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = logreg.predict(x_test)#important\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d56564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the confusion matrix\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "color = 'black'\n",
    "matrix = plot_confusion_matrix(logreg, x_test, y_test, \n",
    "cmap=plt.cm.Blues)\n",
    "matrix.ax_.set_title('Confusion Matrix', color=color)\n",
    "plt.xlabel('Predicted Label', color=color)\n",
    "plt.ylabel('True Label', color=color)\n",
    "plt.gcf().axes[0].tick_params(colors=color)\n",
    "plt.gcf().axes[1].tick_params(colors=color)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n",
    "\n",
    "print(\"Training set score:{:.2f}\".format(logreg.score(x_train,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(x_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca826a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd76745",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dclf = DecisionTreeClassifier()\n",
    "dclf = dclf.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c07bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Mtarix for Decision Tree Classifier\n",
    "y_pred = dclf.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the confusion matrix\n",
    "color = 'black'\n",
    "matrix = plot_confusion_matrix(dclf, x_test, y_test, \n",
    "cmap=plt.cm.Blues)\n",
    "matrix.ax_.set_title('Confusion Matrix', color=color)\n",
    "plt.xlabel('Predicted Label', color=color)\n",
    "plt.ylabel('True Label', color=color)\n",
    "plt.gcf().axes[0].tick_params(colors=color)\n",
    "plt.gcf().axes[1].tick_params(colors=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55907e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n",
    "print(\"Training set score:{:.2f}\".format(dclf.score(x_train,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(dclf.score(x_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b961ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier with Entropy\n",
    "dclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "dclf = dclf.fit(x_train,y_train)\n",
    "print(\"Training set score:{:.2f}\".format(dclf.score(x_train,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(dclf.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95e67c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185358c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random classifier model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, \n",
    "random_state=1)\n",
    "rf = rf.fit(x_train,y_train)\n",
    "print(\"Training set score:{:.2f}\".format(rf.score(x_train,y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(rf.score(x_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad1503",
   "metadata": {},
   "source": [
    "# Pipeline Creation\n",
    "Now we will go ahead and create Pipeline for all the models with which we want our data \n",
    "to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46380497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dae732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also import PCA to perform decomposition or dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecccb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Pipeline creation for Logistic Regression\n",
    "# As our data is already scaled hence we don't need further scaling \n",
    "\n",
    "pipeline_lr = Pipeline([('pca_lr',\n",
    " PCA(n_components = 2)),\n",
    " ('lr_classifier',\n",
    " LogisticRegression(random_state=42))])\n",
    "# Pipeline creation for Decision Tree Classifier\n",
    "pipeline_dt = Pipeline([('pca_dt',\n",
    " PCA(n_components = 2)),\n",
    " ('dt_classifier',\n",
    " DecisionTreeClassifier(criterion=\"entropy\", \n",
    "max_depth=3))])\n",
    "# Pipeline creation for Random Forest Classifier\n",
    "pipeline_rf = Pipeline([('pca_rf',\n",
    " PCA(n_components = 2)),\n",
    " ('rf_classifier',\n",
    " RandomForestClassifier(n_estimators=100, \n",
    "max_depth=3, random_state=42))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6577c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all the Pipelines created\n",
    "pipelines = [pipeline_lr,pipeline_dt,pipeline_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will initialize three variables to showcase that which of the\n",
    "#model is performing the best here\n",
    "# the values will be added in the variable\n",
    "best_accuracy = 0.0\n",
    "best_classifier = 0\n",
    "best_pipeline = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b820e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now initiate a disctionary where key is assigned to each given model\n",
    "\n",
    "pipe_dict = {0:'Logistic regression',\n",
    " 1:'Decision Tree',\n",
    " 2:'Random Forest'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71571a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit our data into the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e72b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will evaluate each model and it's test accuracy with the help of a for loop\n",
    "\n",
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} test accuracy:{:.2f}\".format(pipe_dict[i],model.score(x_test,y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use our previously created variables to define the model specifics \n",
    "\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(x_test,y_test)> best_accuracy:\n",
    "        best_accuracy = model.score(x_test,y_test)\n",
    "        best_pipeline = model\n",
    "        best_classifier = i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354c031",
   "metadata": {},
   "source": [
    "# Pipeline without PCA\n",
    "     We can see our scores decreasing with PCA , let's try creating models without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline creation for Logistic Regression\n",
    "pipeline_lr = Pipeline([('lr_classifier',\n",
    " LogisticRegression(random_state=42))])\n",
    "\n",
    "# Pipeline creation for Decision Tree Classifier\n",
    "pipeline_dt = Pipeline([('dt_classifier',\n",
    " DecisionTreeClassifier(criterion=\"entropy\", \n",
    "max_depth=3))])\n",
    "\n",
    "# Pipeline creation for Random Forest Classifier\n",
    "pipeline_rf = Pipeline([('rf_classifier',\n",
    " RandomForestClassifier(n_estimators=100, \n",
    "max_depth=3, random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95410ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all the Pipelines created\n",
    "pipelines = [pipeline_lr,pipeline_dt,pipeline_rf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will initialize three variables to showcase that which of the model is performing the best here\n",
    "# the values will be added in the variable\n",
    "best_accuracy = 0.0\n",
    "best_classifier = 0\n",
    "best_pipeline = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now initiate a disctionary where key is assigned to each given model\n",
    "pipe_dict = {0:'Logistic regression',\n",
    " 1:'Decision Tree',\n",
    " 2:'Random Forest'}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit our data into the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(x_train,y_train)\n",
    "# Now we will evaluate each model and it's test accuracy with the help  a for loop\n",
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} test accuracy: {:.2f}\".format(pipe_dict[i],model.score(x_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2624ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use our previously created variables to define the model specifics \n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(x_test,y_test)>best_accuracy:\n",
    "        best_accuracy = model.score(x_test,y_test)\n",
    "        best_pipeline = model\n",
    "        best_classifier = i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d126423",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In conclusion, the Titanic dataset provides valuable insight into the tragic event that claimed the lives of passengers and crew members aboard the ill-fated ship.Through data analysis, we can understand the demographics of those onboard, the factors that contributed to the sinking, and the survival rate of different groups. This dataset serves as a reminder of the importance of safety measures and caution when traveling, especially in dangerous situations. Furthermore, it demonstrates the potential of data analysis to uncover patterns and correlations in historical events.\n",
    "\n",
    "Through descriptive statistics we cleaned the dataset. We predict the various model builing to get best accuracy, we can see that without using dimensionality reduction we are able to get better score for our model.We conclude that Classifier with best accuracy:Decision Tree-0.79."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
